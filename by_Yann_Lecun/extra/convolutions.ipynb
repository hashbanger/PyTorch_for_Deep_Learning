{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37064bitpytorchdlcondaece3e48d90fe4f378b2298ced08e3d19",
   "display_name": "Python 3.7.0 64-bit ('pytorchdl': conda)",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Convolutions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "source": [
    "## 1D Convolutions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Conv1d(2, 16, kernel_size=(3,), stride=(1,))"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "conv = nn.Conv1d(2, 16, 3) # 2 channels (assume stereo signal), 16 kernels of size 3\n",
    "conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([16, 2, 3])"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "conv.weight.size() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([16])"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "conv.bias.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[[ 0.2541, -0.8274, -0.9374, -0.6766, -0.3347,  0.3397, -0.2336,\n",
       "           0.5670,  0.0135,  1.0712,  0.4403,  0.2211, -0.1915, -1.6519,\n",
       "          -0.6750, -1.5473,  1.0150, -0.2492,  0.4649,  1.8273,  0.7328,\n",
       "          -0.2198,  0.4638, -0.1005,  1.3831,  0.6270,  1.8321, -0.2153,\n",
       "          -0.2832,  1.5699,  1.9084,  2.4466, -0.1779, -0.2487,  0.1157,\n",
       "          -0.8031, -1.7095,  1.4021,  0.3244,  0.5331, -1.6516, -0.1977,\n",
       "          -0.3379,  1.3615, -0.2133,  0.8629, -0.7841, -0.5295,  3.1171,\n",
       "           1.2273, -0.2677, -0.0868,  0.8791,  1.0471,  0.1599, -1.0634,\n",
       "           0.9788, -0.6566,  0.5963, -0.1734, -0.0843,  0.9240,  0.8134,\n",
       "          -0.2428],\n",
       "         [ 2.6026, -0.1103,  0.7450, -1.3704,  0.0442,  0.9253, -1.7648,\n",
       "          -0.4773,  0.1544,  0.5947,  0.5285, -0.4236,  1.2030,  0.2146,\n",
       "          -0.9988, -1.0654, -0.0957,  0.9927, -0.5874, -1.3259, -1.2192,\n",
       "          -0.3401,  0.4114, -0.3785,  1.2367, -0.8944,  0.7113, -1.2171,\n",
       "           1.2202,  0.1945,  1.7660,  0.0624,  0.4984, -1.1303, -1.1652,\n",
       "          -1.5205,  1.6966,  1.4335, -2.0905,  0.6532,  1.2691, -0.9321,\n",
       "           0.3307,  0.9879,  1.7772,  0.2966,  0.0980, -0.2587, -1.2949,\n",
       "           1.2282,  0.2422, -1.4670, -0.7046,  2.4701,  1.9442,  0.3166,\n",
       "          -0.9603, -0.0524, -1.3637, -1.6418,  0.3965,  0.2640,  0.2962,\n",
       "          -1.0548]]])"
      ]
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": [
    "x = torch.randn(1, 2, 64)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 62])"
      ]
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "conv(x).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = nn.Conv1d(2, 16, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 60])"
      ]
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "source": [
    "conv(x).size()"
   ]
  },
  {
   "source": [
    "## 2D Convolutions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([1, 20, 64, 128])"
      ]
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "source": [
    "x = torch.rand(1, 20, 64, 128) # 1 sample, 20 channels, height 64, and width\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Conv2d(20, 16, kernel_size=(3, 5), stride=(1, 1))"
      ]
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "source": [
    "conv = nn.Conv2d(20, 16, (3, 5)) # 20 channels, 16 kernels, kernel size is 3 x 5\n",
    "conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([16, 20, 3, 5])"
      ]
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "source": [
    "conv.weight.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 62, 124])"
      ]
     },
     "metadata": {},
     "execution_count": 47
    }
   ],
   "source": [
    "conv(x).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Conv2d(20, 16, kernel_size=(3, 5), stride=(1, 1), padding=(1, 2))"
      ]
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "source": [
    "# 20 channels, 16 kernels of size 3 x 5, stride is 1 , padding of 1 and 2\n",
    "conv = nn.Conv2d(20, 16, (3, 5), 1, (1, 2))\n",
    "conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 64, 128])"
      ]
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "source": [
    "conv(x).size()"
   ]
  },
  {
   "source": [
    "## How automatic gradient works?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([1., 2., 3., 4., 5., 6.], requires_grad=True)"
      ]
     },
     "metadata": {},
     "execution_count": 57
    }
   ],
   "source": [
    "n = 6\n",
    "x = torch.arange(1., n + 1, requires_grad = True)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1., 1.], requires_grad=True)"
      ]
     },
     "metadata": {},
     "execution_count": 58
    }
   ],
   "source": [
    "w = torch.ones(n, requires_grad = True)\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(21., grad_fn=<DotBackward>)"
      ]
     },
     "metadata": {},
     "execution_count": 59
    }
   ],
   "source": [
    "z = w @ x\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "z.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([1., 1., 1., 1., 1., 1.])\ntensor([1., 2., 3., 4., 5., 6.])\n"
     ]
    }
   ],
   "source": [
    "print(x.grad, w.grad, sep = '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([1., 2., 3., 4., 5., 6.]),\n",
       " tensor([1., 1., 1., 1., 1., 1.], requires_grad=True))"
      ]
     },
     "metadata": {},
     "execution_count": 63
    }
   ],
   "source": [
    "# having with torch.no_grad() omits gradient accumulation\n",
    "x = torch.arange(1., n + 1)\n",
    "w = torch.ones(n, requires_grad = True)\n",
    "x, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "RuntimeError!!!\nelement 0 of tensors does not require grad and does not have a grad_fn\n"
     ]
    }
   ],
   "source": [
    "# all torch tensors will not have gradient accumulation\n",
    "with torch.no_grad():\n",
    "    z = w @ x \n",
    "\n",
    "try:\n",
    "    z.backward() # error, because z has no grad\n",
    "\n",
    "except RuntimeError as e:\n",
    "    print('RuntimeError!!!')\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}